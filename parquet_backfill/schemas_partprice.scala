case class class_fc_feed_bristol(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_bristol(inpath:String):Dataset[class_fc_feed_bristol]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_bristol(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_standardelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_standardelec(inpath:String):Dataset[class_fc_feed_standardelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_standardelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_apac(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_apac(inpath:String):Dataset[class_fc_feed_chip1stop_apac]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_apac(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_detailtech_cn(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_detailtech_cn(inpath:String):Dataset[class_fc_feed_detailtech_cn]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_detailtech_cn(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_classic(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_classic(inpath:String):Dataset[class_fc_feed_classic]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_classic(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_bnl_jan_2021(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_bnl_jan_2021(inpath:String):Dataset[class_fc_feed_farnell_bnl_jan_2021]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_bnl_jan_2021(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_heilind_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_heilind_oems(inpath:String):Dataset[class_fc_feed_heilind_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_heilind_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_rp_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_rp_bnl(inpath:String):Dataset[class_fc_feed_element14_rp_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_rp_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_mautronics(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_mautronics(inpath:String):Dataset[class_fc_feed_mautronics]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_mautronics(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_fr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_fr(inpath:String):Dataset[class_fc_feed_farnell_fr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_fr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newark_us_bnl2(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newark_us_bnl2(inpath:String):Dataset[class_fc_feed_newark_us_bnl2]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newark_us_bnl2(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_origparts(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_origparts(inpath:String):Dataset[class_fc_feed_origparts]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_origparts(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tme_bnl_fr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tme_bnl_fr(inpath:String):Dataset[class_fc_feed_tme_bnl_fr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tme_bnl_fr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_kedlielec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_kedlielec(inpath:String):Dataset[class_fc_feed_kedlielec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_kedlielec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_fi(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_fi(inpath:String):Dataset[class_fc_feed_farnell_fi]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_fi(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rochester_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rochester_bnl(inpath:String):Dataset[class_fc_feed_rochester_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rochester_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_olc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_olc(inpath:String):Dataset[class_fc_feed_olc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_olc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_galco(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_galco(inpath:String):Dataset[class_fc_feed_galco]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_galco(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_computer_controls(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_computer_controls(inpath:String):Dataset[class_fc_feed_computer_controls]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_computer_controls(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_bnl(inpath:String):Dataset[class_fc_feed_farnell_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_metaverse(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_metaverse(inpath:String):Dataset[class_fc_feed_metaverse]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_metaverse(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_icsoso(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_icsoso(inpath:String):Dataset[class_fc_feed_icsoso]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_icsoso(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_xituo(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_xituo(inpath:String):Dataset[class_fc_feed_xituo]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_xituo(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_usd(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_usd(inpath:String):Dataset[class_fc_feed_chip1stop_usd]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_usd(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_ro_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_ro_findchips(inpath:String):Dataset[class_fc_feed_distrelec_ro_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_ro_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_cny(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_cny(inpath:String):Dataset[class_fc_feed_chip1stop_cny]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_cny(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_fc_it(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_fc_it(inpath:String):Dataset[class_fc_feed_comsit_fc_it]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_fc_it(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_nl_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_nl_findchips(inpath:String):Dataset[class_fc_feed_distrelec_nl_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_nl_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_future_china_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_future_china_fc(inpath:String):Dataset[class_fc_feed_future_china_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_future_china_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_sierraic(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_sierraic(inpath:String):Dataset[class_fc_feed_sierraic]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_sierraic(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_sense_elec_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_sense_elec_fc(inpath:String):Dataset[class_fc_feed_sense_elec_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_sense_elec_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tme_bnl_fi(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tme_bnl_fi(inpath:String):Dataset[class_fc_feed_tme_bnl_fi]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tme_bnl_fi(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_moseley(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_moseley(inpath:String):Dataset[class_fc_feed_moseley]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_moseley(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_ph(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_ph(inpath:String):Dataset[class_fc_feed_element14_ph]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_ph(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_tr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_tr(inpath:String):Dataset[class_fc_feed_rs_components_tr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_tr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_fc_de(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_fc_de(inpath:String):Dataset[class_fc_feed_comsit_fc_de]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_fc_de(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_microworks(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_microworks(inpath:String):Dataset[class_fc_feed_microworks]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_microworks(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_pl_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_pl_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_pl_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_pl_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_fc_in(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_fc_in(inpath:String):Dataset[class_fc_feed_comsit_fc_in]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_fc_in(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_cny_multi(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_cny_multi(inpath:String):Dataset[class_fc_feed_chip1stop_cny_multi]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_cny_multi(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_dk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_dk(inpath:String):Dataset[class_fc_feed_farnell_dk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_dk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_xinghuan(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_xinghuan(inpath:String):Dataset[class_fc_feed_xinghuan]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_xinghuan(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_analog_devices_precision_adc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_analog_devices_precision_adc(inpath:String):Dataset[class_fc_feed_analog_devices_precision_adc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_analog_devices_precision_adc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_jak(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_jak(inpath:String):Dataset[class_fc_feed_jak]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_jak(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_iccomp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_iccomp(inpath:String):Dataset[class_fc_feed_iccomp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_iccomp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_northstar(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_northstar(inpath:String):Dataset[class_fc_feed_northstar]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_northstar(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ameya_fc_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ameya_fc_bnl(inpath:String):Dataset[class_fc_feed_ameya_fc_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ameya_fc_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_cz_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_cz_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_cz_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_cz_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_fc_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_fc_us(inpath:String):Dataset[class_fc_feed_comsit_fc_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_fc_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_compexpert(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_compexpert(inpath:String):Dataset[class_fc_feed_compexpert]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_compexpert(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ickey_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ickey_bnl(inpath:String):Dataset[class_fc_feed_ickey_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ickey_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_hu_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_hu_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_hu_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_hu_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_americas_bnl_now_stocking(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_americas_bnl_now_stocking(inpath:String):Dataset[class_fc_feed_rs_americas_bnl_now_stocking]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_americas_bnl_now_stocking(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis(inpath:String):Dataset[class_fc_feed_peigenesis]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_004_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_004_bnl(inpath:String):Dataset[class_fc_feed_peigenesis_004_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_004_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_quotebeam(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_quotebeam(inpath:String):Dataset[class_fc_feed_quotebeam]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_quotebeam(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_apac(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_apac(inpath:String):Dataset[class_fc_feed_rs_components_apac]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_apac(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_jgm(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_jgm(inpath:String):Dataset[class_fc_feed_jgm]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_jgm(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_usd_oems_3(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_usd_oems_3(inpath:String):Dataset[class_fc_feed_chip1stop_usd_oems_3]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_usd_oems_3(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_future_bnl_optimized(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_future_bnl_optimized(inpath:String):Dataset[class_fc_feed_future_bnl_optimized]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_future_bnl_optimized(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_sg(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_sg(inpath:String):Dataset[class_fc_feed_rs_components_sg]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_sg(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_hklilin(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_hklilin(inpath:String):Dataset[class_fc_feed_hklilin]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_hklilin(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_ch(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_ch(inpath:String):Dataset[class_fc_feed_rspro_ch]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_ch(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ti(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ti(inpath:String):Dataset[class_fc_feed_ti]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ti(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_cz(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_cz(inpath:String):Dataset[class_fc_feed_rspro_cz]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_cz(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rochester_cn_ti_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rochester_cn_ti_bnl(inpath:String):Dataset[class_fc_feed_rochester_cn_ti_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rochester_cn_ti_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_no(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_no(inpath:String):Dataset[class_fc_feed_farnell_no]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_no(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_semtke(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_semtke(inpath:String):Dataset[class_fc_feed_semtke]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_semtke(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rapid(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rapid(inpath:String):Dataset[class_fc_feed_rapid]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rapid(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey_bnl(inpath:String):Dataset[class_fc_feed_digikey_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_avnet_europe(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_avnet_europe(inpath:String):Dataset[class_fc_feed_avnet_europe]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_avnet_europe(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_splendent(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_splendent(inpath:String):Dataset[class_fc_feed_splendent]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_splendent(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey_oems_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey_oems_bnl(inpath:String):Dataset[class_fc_feed_digikey_oems_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey_oems_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey_uk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey_uk(inpath:String):Dataset[class_fc_feed_digikey_uk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey_uk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_breizelec_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_breizelec_oems(inpath:String):Dataset[class_fc_feed_breizelec_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_breizelec_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_be(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_be(inpath:String):Dataset[class_fc_feed_rs_components_be]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_be(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_b2b_rs_components(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_b2b_rs_components(inpath:String):Dataset[class_fc_feed_b2b_rs_components]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_b2b_rs_components(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_futuretech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_futuretech(inpath:String):Dataset[class_fc_feed_futuretech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_futuretech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rutronik_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rutronik_us(inpath:String):Dataset[class_fc_feed_rutronik_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rutronik_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_se(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_se(inpath:String):Dataset[class_fc_feed_rspro_se]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_se(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_b2b(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_b2b(inpath:String):Dataset[class_fc_feed_element14_b2b]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_b2b(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ardusimple_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ardusimple_fc(inpath:String):Dataset[class_fc_feed_ardusimple_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ardusimple_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_rohde_bnl_fr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_rohde_bnl_fr(inpath:String):Dataset[class_fc_feed_farnell_rohde_bnl_fr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_rohde_bnl_fr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tme_bnl_es(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tme_bnl_es(inpath:String):Dataset[class_fc_feed_tme_bnl_es]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tme_bnl_es(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_pl_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_pl_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_pl_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_pl_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_integ(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_integ(inpath:String):Dataset[class_fc_feed_integ]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_integ(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_es(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_es(inpath:String):Dataset[class_fc_feed_farnell_es]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_es(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_hp_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_hp_bnl(inpath:String):Dataset[class_fc_feed_element14_hp_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_hp_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_pl_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_pl_findchips(inpath:String):Dataset[class_fc_feed_distrelec_pl_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_pl_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_sager(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_sager(inpath:String):Dataset[class_fc_feed_sager]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_sager(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tme_bnl_de(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tme_bnl_de(inpath:String):Dataset[class_fc_feed_tme_bnl_de]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tme_bnl_de(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ryx(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ryx(inpath:String):Dataset[class_fc_feed_ryx]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ryx(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ampheo(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ampheo(inpath:String):Dataset[class_fc_feed_ampheo]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ampheo(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rutronik_euro(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rutronik_euro(inpath:String):Dataset[class_fc_feed_rutronik_euro]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rutronik_euro(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_eur_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_eur_oems(inpath:String):Dataset[class_fc_feed_chip1stop_eur_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_eur_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_oneyac_fc_china(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_oneyac_fc_china(inpath:String):Dataset[class_fc_feed_oneyac_fc_china]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_oneyac_fc_china(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newark_bnl_littelfuse(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newark_bnl_littelfuse(inpath:String):Dataset[class_fc_feed_newark_bnl_littelfuse]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newark_bnl_littelfuse(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_eur(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_eur(inpath:String):Dataset[class_fc_feed_chip1stop_eur]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_eur(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_hengshi(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_hengshi(inpath:String):Dataset[class_fc_feed_hengshi]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_hengshi(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_directcomp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_directcomp(inpath:String):Dataset[class_fc_feed_directcomp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_directcomp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_asc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_asc(inpath:String):Dataset[class_fc_feed_asc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_asc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_utmel_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_utmel_fc(inpath:String):Dataset[class_fc_feed_utmel_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_utmel_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ezkey_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ezkey_fc(inpath:String):Dataset[class_fc_feed_ezkey_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ezkey_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_stmicro(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_stmicro(inpath:String):Dataset[class_fc_feed_stmicro]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_stmicro(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_uk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_uk(inpath:String):Dataset[class_fc_feed_rs_components_uk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_uk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_silitech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_silitech(inpath:String):Dataset[class_fc_feed_silitech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_silitech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rochester_jp_ti_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rochester_jp_ti_bnl(inpath:String):Dataset[class_fc_feed_rochester_jp_ti_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rochester_jp_ti_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_fi(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_fi(inpath:String):Dataset[class_fc_feed_rs_components_fi]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_fi(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chipmall_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chipmall_fc(inpath:String):Dataset[class_fc_feed_chipmall_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chipmall_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ozdisan(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ozdisan(inpath:String):Dataset[class_fc_feed_ozdisan]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ozdisan(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_winshare(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_winshare(inpath:String):Dataset[class_fc_feed_winshare]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_winshare(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_mygroup(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_mygroup(inpath:String):Dataset[class_fc_feed_mygroup]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_mygroup(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ysonix(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ysonix(inpath:String):Dataset[class_fc_feed_ysonix]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ysonix(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ti_bnl_dlp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ti_bnl_dlp(inpath:String):Dataset[class_fc_feed_ti_bnl_dlp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ti_bnl_dlp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_testequity_ukie(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_testequity_ukie(inpath:String):Dataset[class_fc_feed_testequity_ukie]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_testequity_ukie(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newadantage_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newadantage_bnl(inpath:String):Dataset[class_fc_feed_newadantage_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newadantage_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_transtector(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_transtector(inpath:String):Dataset[class_fc_feed_transtector]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_transtector(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_techdesign_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_techdesign_oems(inpath:String):Dataset[class_fc_feed_techdesign_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_techdesign_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_heilind_bnl_te(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_heilind_bnl_te(inpath:String):Dataset[class_fc_feed_heilind_bnl_te]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_heilind_bnl_te(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_fr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_fr(inpath:String):Dataset[class_fc_feed_rs_components_fr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_fr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_kruse_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_kruse_oems(inpath:String):Dataset[class_fc_feed_kruse_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_kruse_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_emea(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_emea(inpath:String):Dataset[class_fc_feed_rs_components_emea]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_emea(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_electronicount(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_electronicount(inpath:String):Dataset[class_fc_feed_electronicount]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_electronicount(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_se_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_se_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_se_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_se_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_nacsemi_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_nacsemi_bnl(inpath:String):Dataset[class_fc_feed_nacsemi_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_nacsemi_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_ru(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_ru(inpath:String):Dataset[class_fc_feed_rspro_ru]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_ru(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_de(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_de(inpath:String):Dataset[class_fc_feed_farnell_de]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_de(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_shikues(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_shikues(inpath:String):Dataset[class_fc_feed_shikues]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_shikues(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ibuyxs_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ibuyxs_bnl(inpath:String):Dataset[class_fc_feed_ibuyxs_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ibuyxs_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_ee_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_ee_findchips(inpath:String):Dataset[class_fc_feed_distrelec_ee_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_ee_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_sielectronics(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_sielectronics(inpath:String):Dataset[class_fc_feed_sielectronics]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_sielectronics(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_stockers(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_stockers(inpath:String):Dataset[class_fc_feed_stockers]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_stockers(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_j2(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_j2(inpath:String):Dataset[class_fc_feed_j2]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_j2(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_sense_elec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_sense_elec(inpath:String):Dataset[class_fc_feed_sense_elec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_sense_elec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_bdrtech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_bdrtech(inpath:String):Dataset[class_fc_feed_bdrtech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_bdrtech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_superman(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_superman(inpath:String):Dataset[class_fc_feed_superman]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_superman(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_lcsc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_lcsc(inpath:String):Dataset[class_fc_feed_lcsc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_lcsc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_si(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_si(inpath:String):Dataset[class_fc_feed_farnell_si]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_si(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_global(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_global(inpath:String):Dataset[class_fc_feed_rs_global]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_global(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_us(inpath:String):Dataset[class_fc_feed_peigenesis_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_b2b_comsit(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_b2b_comsit(inpath:String):Dataset[class_fc_feed_b2b_comsit]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_b2b_comsit(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_hengfeng(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_hengfeng(inpath:String):Dataset[class_fc_feed_hengfeng]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_hengfeng(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_nexgen(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_nexgen(inpath:String):Dataset[class_fc_feed_nexgen]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_nexgen(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_no(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_no(inpath:String):Dataset[class_fc_feed_rs_components_no]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_no(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip_digger(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip_digger(inpath:String):Dataset[class_fc_feed_chip_digger]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip_digger(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_it_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_it_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_it_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_it_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey_bnl_lookup(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey_bnl_lookup(inpath:String):Dataset[class_fc_feed_digikey_bnl_lookup]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey_bnl_lookup(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_plcdirect(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_plcdirect(inpath:String):Dataset[class_fc_feed_plcdirect]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_plcdirect(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_master_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_master_oems(inpath:String):Dataset[class_fc_feed_master_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_master_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chipchip(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chipchip(inpath:String):Dataset[class_fc_feed_chipchip]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chipchip(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_lt(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_lt(inpath:String):Dataset[class_fc_feed_farnell_lt]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_lt(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_hongte(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_hongte(inpath:String):Dataset[class_fc_feed_hongte]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_hongte(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_verical_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_verical_bnl(inpath:String):Dataset[class_fc_feed_verical_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_verical_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_bg(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_bg(inpath:String):Dataset[class_fc_feed_farnell_bg]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_bg(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_sk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_sk(inpath:String):Dataset[class_fc_feed_rspro_sk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_sk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_walker(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_walker(inpath:String):Dataset[class_fc_feed_walker]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_walker(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_jpy_oems_2(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_jpy_oems_2(inpath:String):Dataset[class_fc_feed_chip1stop_jpy_oems_2]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_jpy_oems_2(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_electronictreasures(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_electronictreasures(inpath:String):Dataset[class_fc_feed_electronictreasures]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_electronictreasures(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_ie(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_ie(inpath:String):Dataset[class_fc_feed_farnell_ie]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_ie(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_lt_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_lt_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_lt_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_lt_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_bisco_bnl_2022(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_bisco_bnl_2022(inpath:String):Dataset[class_fc_feed_bisco_bnl_2022]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_bisco_bnl_2022(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_at(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_at(inpath:String):Dataset[class_fc_feed_farnell_at]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_at(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_ro(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_ro(inpath:String):Dataset[class_fc_feed_rspro_ro]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_ro(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey_de_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey_de_bnl(inpath:String):Dataset[class_fc_feed_digikey_de_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey_de_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_vigor(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_vigor(inpath:String):Dataset[class_fc_feed_vigor]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_vigor(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_microchip_usa_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_microchip_usa_oems(inpath:String):Dataset[class_fc_feed_microchip_usa_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_microchip_usa_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_nl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_nl(inpath:String):Dataset[class_fc_feed_farnell_nl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_nl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_no_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_no_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_no_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_no_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_dk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_dk(inpath:String):Dataset[class_fc_feed_rs_components_dk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_dk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_yicintl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_yicintl(inpath:String):Dataset[class_fc_feed_yicintl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_yicintl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newadvantage_oems_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newadvantage_oems_us(inpath:String):Dataset[class_fc_feed_newadvantage_oems_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newadvantage_oems_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_lcomus(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_lcomus(inpath:String):Dataset[class_fc_feed_lcomus]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_lcomus(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_bisco(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_bisco(inpath:String):Dataset[class_fc_feed_bisco]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_bisco(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ysyelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ysyelec(inpath:String):Dataset[class_fc_feed_ysyelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ysyelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_hk_keep_booming(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_hk_keep_booming(inpath:String):Dataset[class_fc_feed_hk_keep_booming]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_hk_keep_booming(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_fr_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_fr_findchips(inpath:String):Dataset[class_fc_feed_distrelec_fr_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_fr_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rochester_kr_ti_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rochester_kr_ti_bnl(inpath:String):Dataset[class_fc_feed_rochester_kr_ti_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rochester_kr_ti_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_fairview(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_fairview(inpath:String):Dataset[class_fc_feed_fairview]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_fairview(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_centum(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_centum(inpath:String):Dataset[class_fc_feed_centum]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_centum(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ibuyxs(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ibuyxs(inpath:String):Dataset[class_fc_feed_ibuyxs]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ibuyxs(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ichunt_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ichunt_fc(inpath:String):Dataset[class_fc_feed_ichunt_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ichunt_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_fdh_electronics(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_fdh_electronics(inpath:String):Dataset[class_fc_feed_fdh_electronics]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_fdh_electronics(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_europe_bnl_it(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_europe_bnl_it(inpath:String):Dataset[class_fc_feed_rs_europe_bnl_it]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_europe_bnl_it(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_005(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_005(inpath:String):Dataset[class_fc_feed_peigenesis_005]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_005(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_es(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_es(inpath:String):Dataset[class_fc_feed_rs_components_es]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_es(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tme(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tme(inpath:String):Dataset[class_fc_feed_tme]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tme(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_lcsc_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_lcsc_oems(inpath:String):Dataset[class_fc_feed_lcsc_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_lcsc_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_pasternack_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_pasternack_us(inpath:String):Dataset[class_fc_feed_pasternack_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_pasternack_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_sg(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_sg(inpath:String):Dataset[class_fc_feed_element14_sg]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_sg(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_es_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_es_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_es_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_es_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_ee_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_ee_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_ee_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_ee_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ti_bnl_epd(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ti_bnl_epd(inpath:String):Dataset[class_fc_feed_ti_bnl_epd]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ti_bnl_epd(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_de(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_de(inpath:String):Dataset[class_fc_feed_rs_components_de]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_de(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey_cn_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey_cn_bnl(inpath:String):Dataset[class_fc_feed_digikey_cn_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey_cn_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey_bnl_emea_test(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey_bnl_emea_test(inpath:String):Dataset[class_fc_feed_digikey_bnl_emea_test]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey_bnl_emea_test(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rochester_cn(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rochester_cn(inpath:String):Dataset[class_fc_feed_rochester_cn]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rochester_cn(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_k1tech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_k1tech(inpath:String):Dataset[class_fc_feed_k1tech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_k1tech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_lt_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_lt_findchips(inpath:String):Dataset[class_fc_feed_distrelec_lt_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_lt_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_hu(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_hu(inpath:String):Dataset[class_fc_feed_farnell_hu]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_hu(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ti_bnl_epd2(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ti_bnl_epd2(inpath:String):Dataset[class_fc_feed_ti_bnl_epd2]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ti_bnl_epd2(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_btc_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_btc_oemstrade(inpath:String):Dataset[class_fc_feed_btc_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_btc_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_breizelec_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_breizelec_fc(inpath:String):Dataset[class_fc_feed_breizelec_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_breizelec_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_fcpro_apac(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_fcpro_apac(inpath:String):Dataset[class_fc_feed_farnell_fcpro_apac]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_fcpro_apac(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_icc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_icc(inpath:String):Dataset[class_fc_feed_icc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_icc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_waytek_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_waytek_bnl(inpath:String):Dataset[class_fc_feed_waytek_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_waytek_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_rohde_bnl_de(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_rohde_bnl_de(inpath:String):Dataset[class_fc_feed_farnell_rohde_bnl_de]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_rohde_bnl_de(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ikeyparts(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ikeyparts(inpath:String):Dataset[class_fc_feed_ikeyparts]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ikeyparts(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_link(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_link(inpath:String):Dataset[class_fc_feed_link]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_link(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_fc_mx(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_fc_mx(inpath:String):Dataset[class_fc_feed_comsit_fc_mx]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_fc_mx(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_jingyaorun(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_jingyaorun(inpath:String):Dataset[class_fc_feed_jingyaorun]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_jingyaorun(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_pt_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_pt_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_pt_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_pt_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_renesas_digikey(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_renesas_digikey(inpath:String):Dataset[class_fc_feed_renesas_digikey]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_renesas_digikey(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_lcom(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_lcom(inpath:String):Dataset[class_fc_feed_lcom]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_lcom(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_shirakaba(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_shirakaba(inpath:String):Dataset[class_fc_feed_shirakaba]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_shirakaba(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_pt(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_pt(inpath:String):Dataset[class_fc_feed_rspro_pt]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_pt(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_oems_fr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_oems_fr(inpath:String):Dataset[class_fc_feed_comsit_oems_fr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_oems_fr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ayelectronics(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ayelectronics(inpath:String):Dataset[class_fc_feed_ayelectronics]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ayelectronics(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rochester_ti_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rochester_ti_bnl(inpath:String):Dataset[class_fc_feed_rochester_ti_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rochester_ti_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_dicchip(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_dicchip(inpath:String):Dataset[class_fc_feed_dicchip]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_dicchip(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ti_bnl_hval(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ti_bnl_hval(inpath:String):Dataset[class_fc_feed_ti_bnl_hval]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ti_bnl_hval(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_dk_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_dk_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_dk_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_dk_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rutronik_cn(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rutronik_cn(inpath:String):Dataset[class_fc_feed_rutronik_cn]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rutronik_cn(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rgelek(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rgelek(inpath:String):Dataset[class_fc_feed_rgelek]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rgelek(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_001_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_001_bnl(inpath:String):Dataset[class_fc_feed_peigenesis_001_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_001_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_mouser_bnl_apac(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_mouser_bnl_apac(inpath:String):Dataset[class_fc_feed_mouser_bnl_apac]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_mouser_bnl_apac(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_future_china(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_future_china(inpath:String):Dataset[class_fc_feed_future_china]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_future_china(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ibs(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ibs(inpath:String):Dataset[class_fc_feed_ibs]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ibs(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_global_sourcing(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_global_sourcing(inpath:String):Dataset[class_fc_feed_global_sourcing]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_global_sourcing(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newark_ca(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newark_ca(inpath:String):Dataset[class_fc_feed_newark_ca]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newark_ca(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_nl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_nl(inpath:String):Dataset[class_fc_feed_rs_components_nl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_nl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_adafruit(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_adafruit(inpath:String):Dataset[class_fc_feed_adafruit]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_adafruit(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_drex(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_drex(inpath:String):Dataset[class_fc_feed_drex]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_drex(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_nacsemi_oems_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_nacsemi_oems_us(inpath:String):Dataset[class_fc_feed_nacsemi_oems_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_nacsemi_oems_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_hkcinty(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_hkcinty(inpath:String):Dataset[class_fc_feed_hkcinty]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_hkcinty(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1cloud(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1cloud(inpath:String):Dataset[class_fc_feed_chip1cloud]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1cloud(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_esino(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_esino(inpath:String):Dataset[class_fc_feed_esino]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_esino(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_detailtech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_detailtech(inpath:String):Dataset[class_fc_feed_detailtech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_detailtech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_it_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_it_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_it_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_it_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tme_bnl_it(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tme_bnl_it(inpath:String):Dataset[class_fc_feed_tme_bnl_it]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tme_bnl_it(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_btc_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_btc_findchips(inpath:String):Dataset[class_fc_feed_btc_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_btc_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_oneyac(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_oneyac(inpath:String):Dataset[class_fc_feed_oneyac]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_oneyac(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_olc_bnl_kilovac(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_olc_bnl_kilovac(inpath:String):Dataset[class_fc_feed_olc_bnl_kilovac]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_olc_bnl_kilovac(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_jp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_jp(inpath:String):Dataset[class_fc_feed_farnell_jp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_jp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_superchip(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_superchip(inpath:String):Dataset[class_fc_feed_superchip]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_superchip(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_cgelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_cgelec(inpath:String):Dataset[class_fc_feed_cgelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_cgelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_my(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_my(inpath:String):Dataset[class_fc_feed_rs_components_my]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_my(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_grandpower(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_grandpower(inpath:String):Dataset[class_fc_feed_grandpower]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_grandpower(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_au(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_au(inpath:String):Dataset[class_fc_feed_element14_au]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_au(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_tw(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_tw(inpath:String):Dataset[class_fc_feed_rs_components_tw]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_tw(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_fc_cn(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_fc_cn(inpath:String):Dataset[class_fc_feed_comsit_fc_cn]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_fc_cn(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_shengyu(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_shengyu(inpath:String):Dataset[class_fc_feed_shengyu]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_shengyu(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_opulent(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_opulent(inpath:String):Dataset[class_fc_feed_opulent]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_opulent(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_at(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_at(inpath:String):Dataset[class_fc_feed_rs_components_at]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_at(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ezkey_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ezkey_oems(inpath:String):Dataset[class_fc_feed_ezkey_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ezkey_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_fc_br(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_fc_br(inpath:String):Dataset[class_fc_feed_comsit_fc_br]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_fc_br(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_nl_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_nl_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_nl_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_nl_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_avnet_europe_abacus(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_avnet_europe_abacus(inpath:String):Dataset[class_fc_feed_avnet_europe_abacus]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_avnet_europe_abacus(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_cuidevices(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_cuidevices(inpath:String):Dataset[class_fc_feed_cuidevices]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_cuidevices(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_usd_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_usd_oems(inpath:String):Dataset[class_fc_feed_chip1stop_usd_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_usd_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_burklin(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_burklin(inpath:String):Dataset[class_fc_feed_burklin]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_burklin(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_sehot(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_sehot(inpath:String):Dataset[class_fc_feed_sehot]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_sehot(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tpsglobal(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tpsglobal(inpath:String):Dataset[class_fc_feed_tpsglobal]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tpsglobal(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_cicmaster(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_cicmaster(inpath:String):Dataset[class_fc_feed_cicmaster]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_cicmaster(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey_kr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey_kr(inpath:String):Dataset[class_fc_feed_digikey_kr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey_kr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_dasenic(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_dasenic(inpath:String):Dataset[class_fc_feed_dasenic]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_dasenic(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_americanmicro(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_americanmicro(inpath:String):Dataset[class_fc_feed_americanmicro]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_americanmicro(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_rp_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_rp_bnl(inpath:String):Dataset[class_fc_feed_farnell_rp_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_rp_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newadvantage_fc_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newadvantage_fc_us(inpath:String):Dataset[class_fc_feed_newadvantage_fc_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newadvantage_fc_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_frontview(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_frontview(inpath:String):Dataset[class_fc_feed_frontview]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_frontview(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tme_lookup_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tme_lookup_bnl(inpath:String):Dataset[class_fc_feed_tme_lookup_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tme_lookup_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_compelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_compelec(inpath:String):Dataset[class_fc_feed_compelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_compelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_saiaosi(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_saiaosi(inpath:String):Dataset[class_fc_feed_saiaosi]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_saiaosi(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_us(inpath:String):Dataset[class_fc_feed_rs_components_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_lantana(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_lantana(inpath:String):Dataset[class_fc_feed_lantana]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_lantana(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_be(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_be(inpath:String):Dataset[class_fc_feed_rspro_be]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_be(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_appelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_appelec(inpath:String):Dataset[class_fc_feed_appelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_appelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_it(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_it(inpath:String):Dataset[class_fc_feed_farnell_it]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_it(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_icc_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_icc_bnl(inpath:String):Dataset[class_fc_feed_icc_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_icc_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_verical_global(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_verical_global(inpath:String):Dataset[class_fc_feed_verical_global]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_verical_global(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_molex_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_molex_bnl(inpath:String):Dataset[class_fc_feed_rs_components_molex_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_molex_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_findfpga(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_findfpga(inpath:String):Dataset[class_fc_feed_findfpga]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_findfpga(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_arrow_ads(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_arrow_ads(inpath:String):Dataset[class_fc_feed_arrow_ads]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_arrow_ads(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_americas_bnl_siemens(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_americas_bnl_siemens(inpath:String):Dataset[class_fc_feed_rs_americas_bnl_siemens]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_americas_bnl_siemens(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_powell(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_powell(inpath:String):Dataset[class_fc_feed_powell]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_powell(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_hu(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_hu(inpath:String):Dataset[class_fc_feed_rs_components_hu]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_hu(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey_de(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey_de(inpath:String):Dataset[class_fc_feed_digikey_de]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey_de(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_futuretech_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_futuretech_fc(inpath:String):Dataset[class_fc_feed_futuretech_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_futuretech_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_be_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_be_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_be_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_be_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_coilcraft(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_coilcraft(inpath:String):Dataset[class_fc_feed_coilcraft]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_coilcraft(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_kr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_kr(inpath:String):Dataset[class_fc_feed_rs_components_kr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_kr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_pui(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_pui(inpath:String):Dataset[class_fc_feed_pui]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_pui(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_southchip(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_southchip(inpath:String):Dataset[class_fc_feed_southchip]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_southchip(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_megastar(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_megastar(inpath:String):Dataset[class_fc_feed_megastar]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_megastar(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ameya_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ameya_fc(inpath:String):Dataset[class_fc_feed_ameya_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ameya_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_bestcomp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_bestcomp(inpath:String):Dataset[class_fc_feed_bestcomp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_bestcomp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_heilind_world(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_heilind_world(inpath:String):Dataset[class_fc_feed_heilind_world]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_heilind_world(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tme_bnl_si(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tme_bnl_si(inpath:String):Dataset[class_fc_feed_tme_bnl_si]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tme_bnl_si(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_perfectparts_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_perfectparts_oems(inpath:String):Dataset[class_fc_feed_perfectparts_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_perfectparts_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chuanghan(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chuanghan(inpath:String):Dataset[class_fc_feed_chuanghan]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chuanghan(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_testequity(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_testequity(inpath:String):Dataset[class_fc_feed_testequity]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_testequity(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip_digger_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip_digger_fc(inpath:String):Dataset[class_fc_feed_chip_digger_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip_digger_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_fr_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_fr_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_fr_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_fr_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rutronik_global(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rutronik_global(inpath:String):Dataset[class_fc_feed_rutronik_global]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rutronik_global(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_greenchips_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_greenchips_fc(inpath:String):Dataset[class_fc_feed_greenchips_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_greenchips_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_heisener(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_heisener(inpath:String):Dataset[class_fc_feed_heisener]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_heisener(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_aicreer(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_aicreer(inpath:String):Dataset[class_fc_feed_aicreer]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_aicreer(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_avnet_americas(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_avnet_americas(inpath:String):Dataset[class_fc_feed_avnet_americas]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_avnet_americas(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_005_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_005_bnl(inpath:String):Dataset[class_fc_feed_peigenesis_005_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_005_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_teconn_dynamic_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_teconn_dynamic_bnl(inpath:String):Dataset[class_fc_feed_teconn_dynamic_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_teconn_dynamic_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_de_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_de_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_de_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_de_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_jdcomp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_jdcomp(inpath:String):Dataset[class_fc_feed_jdcomp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_jdcomp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_wuhan(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_wuhan(inpath:String):Dataset[class_fc_feed_wuhan]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_wuhan(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_anterwell(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_anterwell(inpath:String):Dataset[class_fc_feed_anterwell]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_anterwell(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rochester_ru(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rochester_ru(inpath:String):Dataset[class_fc_feed_rochester_ru]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rochester_ru(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_besttech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_besttech(inpath:String):Dataset[class_fc_feed_besttech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_besttech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_cplus(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_cplus(inpath:String):Dataset[class_fc_feed_cplus]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_cplus(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tme_bnl_pl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tme_bnl_pl(inpath:String):Dataset[class_fc_feed_tme_bnl_pl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tme_bnl_pl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_uk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_uk(inpath:String):Dataset[class_fc_feed_rspro_uk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_uk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_powersignal(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_powersignal(inpath:String):Dataset[class_fc_feed_powersignal]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_powersignal(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_resistortoday(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_resistortoday(inpath:String):Dataset[class_fc_feed_resistortoday]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_resistortoday(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_besatech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_besatech(inpath:String):Dataset[class_fc_feed_besatech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_besatech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_corestaff(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_corestaff(inpath:String):Dataset[class_fc_feed_corestaff]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_corestaff(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_fudatonghe(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_fudatonghe(inpath:String):Dataset[class_fc_feed_fudatonghe]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_fudatonghe(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_greenchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_greenchips(inpath:String):Dataset[class_fc_feed_greenchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_greenchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_pl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_pl(inpath:String):Dataset[class_fc_feed_farnell_pl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_pl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_dst(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_dst(inpath:String):Dataset[class_fc_feed_dst]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_dst(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rochester_br_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rochester_br_bnl(inpath:String):Dataset[class_fc_feed_rochester_br_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rochester_br_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_elfaro(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_elfaro(inpath:String):Dataset[class_fc_feed_elfaro]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_elfaro(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_it_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_it_findchips(inpath:String):Dataset[class_fc_feed_distrelec_it_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_it_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_th(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_th(inpath:String):Dataset[class_fc_feed_rs_components_th]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_th(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chipone_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chipone_fc(inpath:String):Dataset[class_fc_feed_chipone_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chipone_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_jp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_jp(inpath:String):Dataset[class_fc_feed_rs_components_jp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_jp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ntemall(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ntemall(inpath:String):Dataset[class_fc_feed_ntemall]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ntemall(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chipspulse_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chipspulse_fc(inpath:String):Dataset[class_fc_feed_chipspulse_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chipspulse_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_tr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_tr(inpath:String):Dataset[class_fc_feed_rspro_tr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_tr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_spartelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_spartelec(inpath:String):Dataset[class_fc_feed_spartelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_spartelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_004(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_004(inpath:String):Dataset[class_fc_feed_peigenesis_004]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_004(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newark_rp_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newark_rp_bnl(inpath:String):Dataset[class_fc_feed_newark_rp_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newark_rp_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_at_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_at_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_at_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_at_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_lv(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_lv(inpath:String):Dataset[class_fc_feed_farnell_lv]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_lv(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_corestaff_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_corestaff_findchips(inpath:String):Dataset[class_fc_feed_corestaff_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_corestaff_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_heilind_americas(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_heilind_americas(inpath:String):Dataset[class_fc_feed_heilind_americas]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_heilind_americas(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_fc(inpath:String):Dataset[class_fc_feed_comsit_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_ch_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_ch_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_ch_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_ch_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_americas_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_americas_bnl(inpath:String):Dataset[class_fc_feed_rs_americas_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_americas_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_flychips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_flychips(inpath:String):Dataset[class_fc_feed_flychips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_flychips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_dovecomp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_dovecomp(inpath:String):Dataset[class_fc_feed_dovecomp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_dovecomp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_unibetter(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_unibetter(inpath:String):Dataset[class_fc_feed_unibetter]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_unibetter(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_it(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_it(inpath:String):Dataset[class_fc_feed_rs_components_it]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_it(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_arrow_bnl_3(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_arrow_bnl_3(inpath:String):Dataset[class_fc_feed_arrow_bnl_3]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_arrow_bnl_3(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_010(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_010(inpath:String):Dataset[class_fc_feed_peigenesis_010]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_010(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_fc_ru(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_fc_ru(inpath:String):Dataset[class_fc_feed_comsit_fc_ru]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_fc_ru(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_lanka(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_lanka(inpath:String):Dataset[class_fc_feed_lanka]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_lanka(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_oems_es(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_oems_es(inpath:String):Dataset[class_fc_feed_comsit_oems_es]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_oems_es(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_future(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_future(inpath:String):Dataset[class_fc_feed_future]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_future(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_macroquest(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_macroquest(inpath:String):Dataset[class_fc_feed_macroquest]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_macroquest(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_compsearch(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_compsearch(inpath:String):Dataset[class_fc_feed_compsearch]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_compsearch(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_heqingelec_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_heqingelec_fc(inpath:String):Dataset[class_fc_feed_heqingelec_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_heqingelec_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_lv_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_lv_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_lv_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_lv_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_burklin_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_burklin_findchips(inpath:String):Dataset[class_fc_feed_burklin_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_burklin_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_unicom(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_unicom(inpath:String):Dataset[class_fc_feed_unicom]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_unicom(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_be_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_be_findchips(inpath:String):Dataset[class_fc_feed_distrelec_be_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_be_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_hp_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_hp_bnl(inpath:String):Dataset[class_fc_feed_farnell_hp_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_hp_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_oems_de(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_oems_de(inpath:String):Dataset[class_fc_feed_comsit_oems_de]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_oems_de(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_xinyixin(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_xinyixin(inpath:String):Dataset[class_fc_feed_xinyixin]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_xinyixin(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_perfectparts(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_perfectparts(inpath:String):Dataset[class_fc_feed_perfectparts]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_perfectparts(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tasnme(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tasnme(inpath:String):Dataset[class_fc_feed_tasnme]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tasnme(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_usd_oems_2(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_usd_oems_2(inpath:String):Dataset[class_fc_feed_chip1stop_usd_oems_2]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_usd_oems_2(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_za_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_za_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_za_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_za_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_b2b_etron(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_b2b_etron(inpath:String):Dataset[class_fc_feed_b2b_etron]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_b2b_etron(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_b2b_corestaff(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_b2b_corestaff(inpath:String):Dataset[class_fc_feed_b2b_corestaff]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_b2b_corestaff(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_karmieltech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_karmieltech(inpath:String):Dataset[class_fc_feed_karmieltech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_karmieltech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_avnet_europe_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_avnet_europe_bnl(inpath:String):Dataset[class_fc_feed_avnet_europe_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_avnet_europe_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_analog_devices(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_analog_devices(inpath:String):Dataset[class_fc_feed_analog_devices]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_analog_devices(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chipstock(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chipstock(inpath:String):Dataset[class_fc_feed_chipstock]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chipstock(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_xidaelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_xidaelec(inpath:String):Dataset[class_fc_feed_xidaelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_xidaelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_no_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_no_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_no_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_no_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_megastar_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_megastar_fc(inpath:String):Dataset[class_fc_feed_megastar_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_megastar_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_oneyac_global(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_oneyac_global(inpath:String):Dataset[class_fc_feed_oneyac_global]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_oneyac_global(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tgmicro(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tgmicro(inpath:String):Dataset[class_fc_feed_tgmicro]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tgmicro(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_szlcsc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_szlcsc(inpath:String):Dataset[class_fc_feed_szlcsc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_szlcsc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newadvantage(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newadvantage(inpath:String):Dataset[class_fc_feed_newadvantage]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newadvantage(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_minamikaze(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_minamikaze(inpath:String):Dataset[class_fc_feed_minamikaze]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_minamikaze(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_lixinc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_lixinc(inpath:String):Dataset[class_fc_feed_lixinc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_lixinc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_iceasy(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_iceasy(inpath:String):Dataset[class_fc_feed_iceasy]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_iceasy(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_arrow_apac_capacitors_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_arrow_apac_capacitors_bnl(inpath:String):Dataset[class_fc_feed_arrow_apac_capacitors_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_arrow_apac_capacitors_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_cz(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_cz(inpath:String):Dataset[class_fc_feed_farnell_cz]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_cz(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_oems_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_oems_us(inpath:String):Dataset[class_fc_feed_comsit_oems_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_oems_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_teledyne_e2v(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_teledyne_e2v(inpath:String):Dataset[class_fc_feed_teledyne_e2v]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_teledyne_e2v(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_at_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_at_findchips(inpath:String):Dataset[class_fc_feed_distrelec_at_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_at_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ztz(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ztz(inpath:String):Dataset[class_fc_feed_ztz]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ztz(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_wanlianxin(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_wanlianxin(inpath:String):Dataset[class_fc_feed_wanlianxin]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_wanlianxin(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_avnet_europe_silica(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_avnet_europe_silica(inpath:String):Dataset[class_fc_feed_avnet_europe_silica]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_avnet_europe_silica(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_ch(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_ch(inpath:String):Dataset[class_fc_feed_farnell_ch]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_ch(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_006_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_006_bnl(inpath:String):Dataset[class_fc_feed_peigenesis_006_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_006_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_icsoeasy(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_icsoeasy(inpath:String):Dataset[class_fc_feed_icsoeasy]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_icsoeasy(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_nacsemi_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_nacsemi_oems(inpath:String):Dataset[class_fc_feed_nacsemi_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_nacsemi_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_global_solutions(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_global_solutions(inpath:String):Dataset[class_fc_feed_global_solutions]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_global_solutions(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_at_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_at_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_at_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_at_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_avnet_europe_ebv(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_avnet_europe_ebv(inpath:String):Dataset[class_fc_feed_avnet_europe_ebv]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_avnet_europe_ebv(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_eur_oems_3(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_eur_oems_3(inpath:String):Dataset[class_fc_feed_chip1stop_eur_oems_3]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_eur_oems_3(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_oems_in(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_oems_in(inpath:String):Dataset[class_fc_feed_comsit_oems_in]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_oems_in(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_esonic(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_esonic(inpath:String):Dataset[class_fc_feed_esonic]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_esonic(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_es(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_es(inpath:String):Dataset[class_fc_feed_rspro_es]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_es(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tme_bnl_cz(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tme_bnl_cz(inpath:String):Dataset[class_fc_feed_tme_bnl_cz]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tme_bnl_cz(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_fi_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_fi_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_fi_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_fi_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_pl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_pl(inpath:String):Dataset[class_fc_feed_rs_components_pl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_pl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_ch_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_ch_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_ch_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_ch_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_velocity(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_velocity(inpath:String):Dataset[class_fc_feed_velocity]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_velocity(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_componentsolutions(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_componentsolutions(inpath:String):Dataset[class_fc_feed_componentsolutions]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_componentsolutions(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_macroship(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_macroship(inpath:String):Dataset[class_fc_feed_macroship]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_macroship(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_avnet_japan(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_avnet_japan(inpath:String):Dataset[class_fc_feed_avnet_japan]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_avnet_japan(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ibuyxs_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ibuyxs_fc(inpath:String):Dataset[class_fc_feed_ibuyxs_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ibuyxs_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chipspulse_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chipspulse_bnl(inpath:String):Dataset[class_fc_feed_chipspulse_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chipspulse_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_lv_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_lv_findchips(inpath:String):Dataset[class_fc_feed_distrelec_lv_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_lv_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_my(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_my(inpath:String):Dataset[class_fc_feed_element14_my]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_my(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_fcpro_emea(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_fcpro_emea(inpath:String):Dataset[class_fc_feed_farnell_fcpro_emea]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_fcpro_emea(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_spectrum(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_spectrum(inpath:String):Dataset[class_fc_feed_spectrum]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_spectrum(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_hk_tw_kr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_hk_tw_kr(inpath:String):Dataset[class_fc_feed_chip1stop_hk_tw_kr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_hk_tw_kr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_de_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_de_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_de_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_de_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rxelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rxelec(inpath:String):Dataset[class_fc_feed_rxelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rxelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_ie(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_ie(inpath:String):Dataset[class_fc_feed_rs_components_ie]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_ie(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_007(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_007(inpath:String):Dataset[class_fc_feed_peigenesis_007]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_007(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_commoditycomp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_commoditycomp(inpath:String):Dataset[class_fc_feed_commoditycomp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_commoditycomp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_nxp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_nxp(inpath:String):Dataset[class_fc_feed_nxp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_nxp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1cloud_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1cloud_fc(inpath:String):Dataset[class_fc_feed_chip1cloud_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1cloud_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_symmetry_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_symmetry_fc(inpath:String):Dataset[class_fc_feed_symmetry_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_symmetry_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_heilind_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_heilind_bnl(inpath:String):Dataset[class_fc_feed_heilind_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_heilind_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_melchioni(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_melchioni(inpath:String):Dataset[class_fc_feed_melchioni]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_melchioni(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_intercard(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_intercard(inpath:String):Dataset[class_fc_feed_intercard]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_intercard(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_egbtech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_egbtech(inpath:String):Dataset[class_fc_feed_egbtech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_egbtech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_greenlight(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_greenlight(inpath:String):Dataset[class_fc_feed_greenlight]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_greenlight(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_semix(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_semix(inpath:String):Dataset[class_fc_feed_semix]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_semix(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tobyelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tobyelec(inpath:String):Dataset[class_fc_feed_tobyelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tobyelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_de_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_de_findchips(inpath:String):Dataset[class_fc_feed_distrelec_de_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_de_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_nl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_nl(inpath:String):Dataset[class_fc_feed_rspro_nl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_nl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_bnl_2(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_bnl_2(inpath:String):Dataset[class_fc_feed_farnell_bnl_2]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_bnl_2(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_teconn_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_teconn_bnl(inpath:String):Dataset[class_fc_feed_teconn_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_teconn_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_th(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_th(inpath:String):Dataset[class_fc_feed_element14_th]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_th(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_001(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_001(inpath:String):Dataset[class_fc_feed_peigenesis_001]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_001(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rjcomp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rjcomp(inpath:String):Dataset[class_fc_feed_rjcomp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rjcomp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_no_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_no_findchips(inpath:String):Dataset[class_fc_feed_distrelec_no_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_no_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_cn(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_cn(inpath:String):Dataset[class_fc_feed_rs_components_cn]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_cn(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_avnet_bnl_americas(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_avnet_bnl_americas(inpath:String):Dataset[class_fc_feed_avnet_bnl_americas]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_avnet_bnl_americas(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_visioncomp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_visioncomp(inpath:String):Dataset[class_fc_feed_visioncomp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_visioncomp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_usd_multi(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_usd_multi(inpath:String):Dataset[class_fc_feed_chip1stop_usd_multi]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_usd_multi(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_gangbo(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_gangbo(inpath:String):Dataset[class_fc_feed_gangbo]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_gangbo(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_wenorca(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_wenorca(inpath:String):Dataset[class_fc_feed_wenorca]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_wenorca(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_semihouse(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_semihouse(inpath:String):Dataset[class_fc_feed_semihouse]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_semihouse(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_sekorm(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_sekorm(inpath:String):Dataset[class_fc_feed_sekorm]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_sekorm(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_winsource(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_winsource(inpath:String):Dataset[class_fc_feed_winsource]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_winsource(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_sitime(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_sitime(inpath:String):Dataset[class_fc_feed_sitime]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_sitime(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_converge(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_converge(inpath:String):Dataset[class_fc_feed_converge]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_converge(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_kr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_kr(inpath:String):Dataset[class_fc_feed_element14_kr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_kr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_americas_dynamic(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_americas_dynamic(inpath:String):Dataset[class_fc_feed_rs_americas_dynamic]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_americas_dynamic(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_future_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_future_bnl(inpath:String):Dataset[class_fc_feed_future_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_future_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey_cn_b2b(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey_cn_b2b(inpath:String):Dataset[class_fc_feed_digikey_cn_b2b]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey_cn_b2b(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_ch_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_ch_findchips(inpath:String):Dataset[class_fc_feed_distrelec_ch_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_ch_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_ru(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_ru(inpath:String):Dataset[class_fc_feed_farnell_ru]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_ru(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chipmh(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chipmh(inpath:String):Dataset[class_fc_feed_chipmh]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chipmh(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_linkinv(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_linkinv(inpath:String):Dataset[class_fc_feed_linkinv]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_linkinv(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_kenawang(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_kenawang(inpath:String):Dataset[class_fc_feed_kenawang]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_kenawang(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_fi(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_fi(inpath:String):Dataset[class_fc_feed_rspro_fi]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_fi(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_zxd(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_zxd(inpath:String):Dataset[class_fc_feed_zxd]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_zxd(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_fr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_fr(inpath:String):Dataset[class_fc_feed_rspro_fr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_fr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_avnet_asia(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_avnet_asia(inpath:String):Dataset[class_fc_feed_avnet_asia]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_avnet_asia(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_sensible(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_sensible(inpath:String):Dataset[class_fc_feed_sensible]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_sensible(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_hongxinwei(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_hongxinwei(inpath:String):Dataset[class_fc_feed_hongxinwei]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_hongxinwei(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_amplechip(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_amplechip(inpath:String):Dataset[class_fc_feed_amplechip]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_amplechip(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_fi_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_fi_findchips(inpath:String):Dataset[class_fc_feed_distrelec_fi_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_fi_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_escomp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_escomp(inpath:String):Dataset[class_fc_feed_escomp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_escomp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_hkdcy(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_hkdcy(inpath:String):Dataset[class_fc_feed_hkdcy]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_hkdcy(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_inventorymp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_inventorymp(inpath:String):Dataset[class_fc_feed_inventorymp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_inventorymp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_za(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_za(inpath:String):Dataset[class_fc_feed_rs_components_za]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_za(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_nacsemi(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_nacsemi(inpath:String):Dataset[class_fc_feed_nacsemi]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_nacsemi(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_vanda(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_vanda(inpath:String):Dataset[class_fc_feed_vanda]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_vanda(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ti_bnl_epd1(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ti_bnl_epd1(inpath:String):Dataset[class_fc_feed_ti_bnl_epd1]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ti_bnl_epd1(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_finestock(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_finestock(inpath:String):Dataset[class_fc_feed_finestock]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_finestock(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_oems(inpath:String):Dataset[class_fc_feed_comsit_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_sk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_sk(inpath:String):Dataset[class_fc_feed_farnell_sk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_sk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_wpg_americas(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_wpg_americas(inpath:String):Dataset[class_fc_feed_wpg_americas]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_wpg_americas(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_global_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_global_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_global_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_global_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_greentree(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_greentree(inpath:String):Dataset[class_fc_feed_greentree]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_greentree(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_dk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_dk(inpath:String):Dataset[class_fc_feed_rspro_dk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_dk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_richelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_richelec(inpath:String):Dataset[class_fc_feed_richelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_richelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_ro(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_ro(inpath:String):Dataset[class_fc_feed_farnell_ro]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_ro(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_arrow(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_arrow(inpath:String):Dataset[class_fc_feed_arrow]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_arrow(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_master(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_master(inpath:String):Dataset[class_fc_feed_master]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_master(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_globaltek(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_globaltek(inpath:String):Dataset[class_fc_feed_globaltek]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_globaltek(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_etchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_etchips(inpath:String):Dataset[class_fc_feed_etchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_etchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_xsource(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_xsource(inpath:String):Dataset[class_fc_feed_xsource]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_xsource(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_cz(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_cz(inpath:String):Dataset[class_fc_feed_rs_components_cz]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_cz(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_nacsemi_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_nacsemi_fc(inpath:String):Dataset[class_fc_feed_nacsemi_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_nacsemi_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_ch(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_ch(inpath:String):Dataset[class_fc_feed_rs_components_ch]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_ch(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_oems_it(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_oems_it(inpath:String):Dataset[class_fc_feed_comsit_oems_it]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_oems_it(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_ie_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_ie_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_ie_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_ie_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_eur_multi(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_eur_multi(inpath:String):Dataset[class_fc_feed_chip1stop_eur_multi]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_eur_multi(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_avnet_americas_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_avnet_americas_bnl(inpath:String):Dataset[class_fc_feed_avnet_americas_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_avnet_americas_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ti_bnl_app(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ti_bnl_app(inpath:String):Dataset[class_fc_feed_ti_bnl_app]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ti_bnl_app(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_no(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_no(inpath:String):Dataset[class_fc_feed_rspro_no]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_no(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_nz(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_nz(inpath:String):Dataset[class_fc_feed_rs_components_nz]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_nz(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_us_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_us_bnl(inpath:String):Dataset[class_fc_feed_peigenesis_us_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_us_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newstrength(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newstrength(inpath:String):Dataset[class_fc_feed_newstrength]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newstrength(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peerless(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peerless(inpath:String):Dataset[class_fc_feed_peerless]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peerless(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_dgttech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_dgttech(inpath:String):Dataset[class_fc_feed_dgttech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_dgttech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_jpy_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_jpy_oems(inpath:String):Dataset[class_fc_feed_chip1stop_jpy_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_jpy_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_ro_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_ro_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_ro_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_ro_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_kstcomp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_kstcomp(inpath:String):Dataset[class_fc_feed_kstcomp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_kstcomp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_forward(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_forward(inpath:String):Dataset[class_fc_feed_forward]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_forward(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_weyland(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_weyland(inpath:String):Dataset[class_fc_feed_weyland]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_weyland(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_littletech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_littletech(inpath:String):Dataset[class_fc_feed_littletech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_littletech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_molex(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_molex(inpath:String):Dataset[class_fc_feed_molex]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_molex(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_oneyac_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_oneyac_oems(inpath:String):Dataset[class_fc_feed_oneyac_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_oneyac_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_zhongkaixin(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_zhongkaixin(inpath:String):Dataset[class_fc_feed_zhongkaixin]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_zhongkaixin(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chipspulse(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chipspulse(inpath:String):Dataset[class_fc_feed_chipspulse]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chipspulse(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop(inpath:String):Dataset[class_fc_feed_chip1stop]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_se_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_se_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_se_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_se_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_bnl_littelfuse(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_bnl_littelfuse(inpath:String):Dataset[class_fc_feed_farnell_bnl_littelfuse]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_bnl_littelfuse(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_netsight(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_netsight(inpath:String):Dataset[class_fc_feed_netsight]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_netsight(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_btwelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_btwelec(inpath:String):Dataset[class_fc_feed_btwelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_btwelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_heilind_europe(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_heilind_europe(inpath:String):Dataset[class_fc_feed_heilind_europe]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_heilind_europe(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_allied_findchips_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_allied_findchips_us(inpath:String):Dataset[class_fc_feed_allied_findchips_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_allied_findchips_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_relayspec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_relayspec(inpath:String):Dataset[class_fc_feed_relayspec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_relayspec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_electroshield(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_electroshield(inpath:String):Dataset[class_fc_feed_electroshield]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_electroshield(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_cz_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_cz_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_cz_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_cz_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ameya_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ameya_oems(inpath:String):Dataset[class_fc_feed_ameya_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ameya_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_techdesign(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_techdesign(inpath:String):Dataset[class_fc_feed_techdesign]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_techdesign(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_teamgene(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_teamgene(inpath:String):Dataset[class_fc_feed_teamgene]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_teamgene(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_macroquest_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_macroquest_fc(inpath:String):Dataset[class_fc_feed_macroquest_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_macroquest_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_oems(inpath:String):Dataset[class_fc_feed_distrelec_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_neutron(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_neutron(inpath:String):Dataset[class_fc_feed_neutron]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_neutron(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_amh(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_amh(inpath:String):Dataset[class_fc_feed_amh]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_amh(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_globx(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_globx(inpath:String):Dataset[class_fc_feed_globx]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_globx(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_touchstone_systems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_touchstone_systems(inpath:String):Dataset[class_fc_feed_touchstone_systems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_touchstone_systems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_lukelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_lukelec(inpath:String):Dataset[class_fc_feed_lukelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_lukelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_dk_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_dk_findchips(inpath:String):Dataset[class_fc_feed_distrelec_dk_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_dk_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_waytek_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_waytek_fc(inpath:String):Dataset[class_fc_feed_waytek_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_waytek_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_it(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_it(inpath:String):Dataset[class_fc_feed_rspro_it]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_it(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_b2b_cecport(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_b2b_cecport(inpath:String):Dataset[class_fc_feed_b2b_cecport]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_b2b_cecport(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_erize(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_erize(inpath:String):Dataset[class_fc_feed_erize]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_erize(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_murata_cn(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_murata_cn(inpath:String):Dataset[class_fc_feed_murata_cn]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_murata_cn(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chiefent(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chiefent(inpath:String):Dataset[class_fc_feed_chiefent]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chiefent(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ecco(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ecco(inpath:String):Dataset[class_fc_feed_ecco]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ecco(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_icpartner(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_icpartner(inpath:String):Dataset[class_fc_feed_icpartner]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_icpartner(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_tw(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_tw(inpath:String):Dataset[class_fc_feed_element14_tw]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_tw(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_de(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_de(inpath:String):Dataset[class_fc_feed_rspro_de]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_de(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey(inpath:String):Dataset[class_fc_feed_digikey]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_vyrian(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_vyrian(inpath:String):Dataset[class_fc_feed_vyrian]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_vyrian(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_electrocraft(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_electrocraft(inpath:String):Dataset[class_fc_feed_electrocraft]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_electrocraft(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_global_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_global_findchips(inpath:String):Dataset[class_fc_feed_distrelec_global_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_global_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_vast_global(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_vast_global(inpath:String):Dataset[class_fc_feed_vast_global]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_vast_global(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_arrow_bnl_smp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_arrow_bnl_smp(inpath:String):Dataset[class_fc_feed_arrow_bnl_smp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_arrow_bnl_smp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ichunt(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ichunt(inpath:String):Dataset[class_fc_feed_ichunt]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ichunt(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_avnet_japan_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_avnet_japan_bnl(inpath:String):Dataset[class_fc_feed_avnet_japan_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_avnet_japan_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_in(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_in(inpath:String):Dataset[class_fc_feed_element14_in]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_in(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_electroent(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_electroent(inpath:String):Dataset[class_fc_feed_electroent]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_electroent(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rochester(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rochester(inpath:String):Dataset[class_fc_feed_rochester]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rochester(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_uk_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_uk_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_uk_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_uk_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey_cn(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey_cn(inpath:String):Dataset[class_fc_feed_digikey_cn]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey_cn(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newideas(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newideas(inpath:String):Dataset[class_fc_feed_newideas]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newideas(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_se(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_se(inpath:String):Dataset[class_fc_feed_farnell_se]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_se(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_shenghuayuan(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_shenghuayuan(inpath:String):Dataset[class_fc_feed_shenghuayuan]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_shenghuayuan(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_directcomp_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_directcomp_fc(inpath:String):Dataset[class_fc_feed_directcomp_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_directcomp_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit(inpath:String):Dataset[class_fc_feed_comsit]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_flipelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_flipelec(inpath:String):Dataset[class_fc_feed_flipelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_flipelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_cn(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_cn(inpath:String):Dataset[class_fc_feed_element14_cn]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_cn(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_winsource_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_winsource_fc(inpath:String):Dataset[class_fc_feed_winsource_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_winsource_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_available(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_available(inpath:String):Dataset[class_fc_feed_comsit_available]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_available(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_oems_cn(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_oems_cn(inpath:String):Dataset[class_fc_feed_comsit_oems_cn]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_oems_cn(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_icchipshop(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_icchipshop(inpath:String):Dataset[class_fc_feed_icchipshop]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_icchipshop(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_venatech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_venatech(inpath:String):Dataset[class_fc_feed_venatech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_venatech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_future_cn_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_future_cn_bnl(inpath:String):Dataset[class_fc_feed_future_cn_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_future_cn_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_incielcom(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_incielcom(inpath:String):Dataset[class_fc_feed_incielcom]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_incielcom(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tlc_electronics(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tlc_electronics(inpath:String):Dataset[class_fc_feed_tlc_electronics]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tlc_electronics(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_pasternack(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_pasternack(inpath:String):Dataset[class_fc_feed_pasternack]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_pasternack(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_b2b_chip1stop(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_b2b_chip1stop(inpath:String):Dataset[class_fc_feed_b2b_chip1stop]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_b2b_chip1stop(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_hongyinwei(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_hongyinwei(inpath:String):Dataset[class_fc_feed_hongyinwei]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_hongyinwei(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_sk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_sk(inpath:String):Dataset[class_fc_feed_rs_components_sk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_sk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_cdmelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_cdmelec(inpath:String):Dataset[class_fc_feed_cdmelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_cdmelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_se_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_se_findchips(inpath:String):Dataset[class_fc_feed_distrelec_se_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_se_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newadvantage_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newadvantage_fc(inpath:String):Dataset[class_fc_feed_newadvantage_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newadvantage_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip_germany(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip_germany(inpath:String):Dataset[class_fc_feed_chip_germany]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip_germany(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_nacsemi_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_nacsemi_us(inpath:String):Dataset[class_fc_feed_nacsemi_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_nacsemi_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_semour(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_semour(inpath:String):Dataset[class_fc_feed_semour]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_semour(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newark_hp_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newark_hp_bnl(inpath:String):Dataset[class_fc_feed_newark_hp_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newark_hp_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_allied_oemstrade_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_allied_oemstrade_us(inpath:String):Dataset[class_fc_feed_allied_oemstrade_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_allied_oemstrade_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_fi_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_fi_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_fi_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_fi_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_ro(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_ro(inpath:String):Dataset[class_fc_feed_rs_components_ro]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_ro(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_hk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_hk(inpath:String):Dataset[class_fc_feed_rs_components_hk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_hk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_flip_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_flip_fc(inpath:String):Dataset[class_fc_feed_flip_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_flip_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_polyphaser(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_polyphaser(inpath:String):Dataset[class_fc_feed_polyphaser]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_polyphaser(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_flywing(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_flywing(inpath:String):Dataset[class_fc_feed_flywing]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_flywing(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_flyking(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_flyking(inpath:String):Dataset[class_fc_feed_flyking]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_flyking(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_component_stockers(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_component_stockers(inpath:String):Dataset[class_fc_feed_component_stockers]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_component_stockers(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_003_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_003_bnl(inpath:String):Dataset[class_fc_feed_peigenesis_003_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_003_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_cny_oems_3(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_cny_oems_3(inpath:String):Dataset[class_fc_feed_chip1stop_cny_oems_3]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_cny_oems_3(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_kruse_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_kruse_fc(inpath:String):Dataset[class_fc_feed_kruse_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_kruse_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ystchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ystchips(inpath:String):Dataset[class_fc_feed_ystchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ystchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_cxda(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_cxda(inpath:String):Dataset[class_fc_feed_cxda]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_cxda(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_ie(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_ie(inpath:String):Dataset[class_fc_feed_rspro_ie]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_ie(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_americas_bnl_rs_pro(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_americas_bnl_rs_pro(inpath:String):Dataset[class_fc_feed_rs_americas_bnl_rs_pro]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_americas_bnl_rs_pro(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_dynamic_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_dynamic_fc(inpath:String):Dataset[class_fc_feed_dynamic_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_dynamic_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_at(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_at(inpath:String):Dataset[class_fc_feed_rspro_at]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_at(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_oems_br(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_oems_br(inpath:String):Dataset[class_fc_feed_comsit_oems_br]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_oems_br(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_heilind_asia_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_heilind_asia_oems(inpath:String):Dataset[class_fc_feed_heilind_asia_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_heilind_asia_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_jrh(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_jrh(inpath:String):Dataset[class_fc_feed_jrh]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_jrh(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_vrgcomp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_vrgcomp(inpath:String):Dataset[class_fc_feed_vrgcomp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_vrgcomp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newark_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newark_us(inpath:String):Dataset[class_fc_feed_newark_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newark_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_springtech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_springtech(inpath:String):Dataset[class_fc_feed_springtech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_springtech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_cz_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_cz_findchips(inpath:String):Dataset[class_fc_feed_distrelec_cz_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_cz_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_waytek(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_waytek(inpath:String):Dataset[class_fc_feed_waytek]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_waytek(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_be(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_be(inpath:String):Dataset[class_fc_feed_farnell_be]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_be(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_viczone(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_viczone(inpath:String):Dataset[class_fc_feed_viczone]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_viczone(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_be_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_be_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_be_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_be_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_aepetsche(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_aepetsche(inpath:String):Dataset[class_fc_feed_aepetsche]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_aepetsche(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_bitfoic(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_bitfoic(inpath:String):Dataset[class_fc_feed_bitfoic]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_bitfoic(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newadvantage_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newadvantage_oems(inpath:String):Dataset[class_fc_feed_newadvantage_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newadvantage_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_aps(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_aps(inpath:String):Dataset[class_fc_feed_aps]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_aps(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell(inpath:String):Dataset[class_fc_feed_farnell]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_westcoast(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_westcoast(inpath:String):Dataset[class_fc_feed_westcoast]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_westcoast(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_hu(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_hu(inpath:String):Dataset[class_fc_feed_rspro_hu]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_hu(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_microchip_usa(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_microchip_usa(inpath:String):Dataset[class_fc_feed_microchip_usa]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_microchip_usa(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_ee(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_ee(inpath:String):Dataset[class_fc_feed_farnell_ee]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_ee(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_vyrian_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_vyrian_fc(inpath:String):Dataset[class_fc_feed_vyrian_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_vyrian_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_samno(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_samno(inpath:String):Dataset[class_fc_feed_samno]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_samno(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tme_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tme_oems(inpath:String):Dataset[class_fc_feed_tme_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tme_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_avnet_dp_nmi_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_avnet_dp_nmi_bnl(inpath:String):Dataset[class_fc_feed_avnet_dp_nmi_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_avnet_dp_nmi_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_dbroberts(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_dbroberts(inpath:String):Dataset[class_fc_feed_dbroberts]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_dbroberts(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_jpy_oems_3(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_jpy_oems_3(inpath:String):Dataset[class_fc_feed_chip1stop_jpy_oems_3]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_jpy_oems_3(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_wbchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_wbchips(inpath:String):Dataset[class_fc_feed_wbchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_wbchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_allied_oemstrade_ex(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_allied_oemstrade_ex(inpath:String):Dataset[class_fc_feed_allied_oemstrade_ex]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_allied_oemstrade_ex(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_diverse(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_diverse(inpath:String):Dataset[class_fc_feed_diverse]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_diverse(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rochester_discounted_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rochester_discounted_bnl(inpath:String):Dataset[class_fc_feed_rochester_discounted_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rochester_discounted_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_samtec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_samtec(inpath:String):Dataset[class_fc_feed_samtec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_samtec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_briocean(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_briocean(inpath:String):Dataset[class_fc_feed_briocean]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_briocean(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_kronex(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_kronex(inpath:String):Dataset[class_fc_feed_kronex]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_kronex(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_circular(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_circular(inpath:String):Dataset[class_fc_feed_circular]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_circular(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_uk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_uk(inpath:String):Dataset[class_fc_feed_farnell_uk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_uk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_statemotor(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_statemotor(inpath:String):Dataset[class_fc_feed_statemotor]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_statemotor(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_b2b_wpg(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_b2b_wpg(inpath:String):Dataset[class_fc_feed_b2b_wpg]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_b2b_wpg(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_hu_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_hu_bnl(inpath:String):Dataset[class_fc_feed_farnell_hu_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_hu_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_waytek_feed_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_waytek_feed_bnl(inpath:String):Dataset[class_fc_feed_waytek_feed_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_waytek_feed_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_bnl_littelfuse(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_bnl_littelfuse(inpath:String):Dataset[class_fc_feed_element14_bnl_littelfuse]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_bnl_littelfuse(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_nacsemi_findchips_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_nacsemi_findchips_bnl(inpath:String):Dataset[class_fc_feed_nacsemi_findchips_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_nacsemi_findchips_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chipmall(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chipmall(inpath:String):Dataset[class_fc_feed_chipmall]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chipmall(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_suishen_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_suishen_oems(inpath:String):Dataset[class_fc_feed_suishen_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_suishen_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_heilind_europe_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_heilind_europe_oems(inpath:String):Dataset[class_fc_feed_heilind_europe_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_heilind_europe_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_iconline(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_iconline(inpath:String):Dataset[class_fc_feed_iconline]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_iconline(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_assetgreen(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_assetgreen(inpath:String):Dataset[class_fc_feed_assetgreen]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_assetgreen(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rfpd(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rfpd(inpath:String):Dataset[class_fc_feed_rfpd]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rfpd(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_nacsemi_fc_us(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_nacsemi_fc_us(inpath:String):Dataset[class_fc_feed_nacsemi_fc_us]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_nacsemi_fc_us(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_teconn(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_teconn(inpath:String):Dataset[class_fc_feed_teconn]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_teconn(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_ph(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_ph(inpath:String):Dataset[class_fc_feed_rs_components_ph]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_ph(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_dynamic(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_dynamic(inpath:String):Dataset[class_fc_feed_dynamic]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_dynamic(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_nz(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_nz(inpath:String):Dataset[class_fc_feed_element14_nz]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_nz(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_schukat_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_schukat_fc(inpath:String):Dataset[class_fc_feed_schukat_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_schukat_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rutronik(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rutronik(inpath:String):Dataset[class_fc_feed_rutronik]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rutronik(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_se(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_se(inpath:String):Dataset[class_fc_feed_rs_components_se]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_se(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_fc_es(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_fc_es(inpath:String):Dataset[class_fc_feed_comsit_fc_es]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_fc_es(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_maritex(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_maritex(inpath:String):Dataset[class_fc_feed_maritex]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_maritex(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_southelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_southelec(inpath:String):Dataset[class_fc_feed_southelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_southelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newadvantage_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newadvantage_bnl(inpath:String):Dataset[class_fc_feed_newadvantage_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newadvantage_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_microchip(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_microchip(inpath:String):Dataset[class_fc_feed_microchip]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_microchip(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ti_bnl_asc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ti_bnl_asc(inpath:String):Dataset[class_fc_feed_ti_bnl_asc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ti_bnl_asc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_walkerind(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_walkerind(inpath:String):Dataset[class_fc_feed_walkerind]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_walkerind(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_libra(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_libra(inpath:String):Dataset[class_fc_feed_libra]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_libra(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_sk_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_sk_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_sk_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_sk_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_mvcomp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_mvcomp(inpath:String):Dataset[class_fc_feed_mvcomp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_mvcomp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_arrow_bnl_2(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_arrow_bnl_2(inpath:String):Dataset[class_fc_feed_arrow_bnl_2]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_arrow_bnl_2(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14(inpath:String):Dataset[class_fc_feed_element14]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_shengyu_fc(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_shengyu_fc(inpath:String):Dataset[class_fc_feed_shengyu_fc]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_shengyu_fc(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_003(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_003(inpath:String):Dataset[class_fc_feed_peigenesis_003]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_003(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_terapart(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_terapart(inpath:String):Dataset[class_fc_feed_terapart]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_terapart(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_vn(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_vn(inpath:String):Dataset[class_fc_feed_element14_vn]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_vn(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_jameco(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_jameco(inpath:String):Dataset[class_fc_feed_jameco]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_jameco(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_symmetry_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_symmetry_oems(inpath:String):Dataset[class_fc_feed_symmetry_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_symmetry_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec(inpath:String):Dataset[class_fc_feed_distrelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_gallop(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_gallop(inpath:String):Dataset[class_fc_feed_gallop]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_gallop(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_heilind_americas_asia(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_heilind_americas_asia(inpath:String):Dataset[class_fc_feed_heilind_americas_asia]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_heilind_americas_asia(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_oems_mx(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_oems_mx(inpath:String):Dataset[class_fc_feed_comsit_oems_mx]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_oems_mx(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_ru(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_ru(inpath:String):Dataset[class_fc_feed_rs_components_ru]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_ru(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_peigenesis_006(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_peigenesis_006(inpath:String):Dataset[class_fc_feed_peigenesis_006]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_peigenesis_006(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_oneyac_fc_global(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_oneyac_fc_global(inpath:String):Dataset[class_fc_feed_oneyac_fc_global]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_oneyac_fc_global(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey_hk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey_hk(inpath:String):Dataset[class_fc_feed_digikey_hk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey_hk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_acds(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_acds(inpath:String):Dataset[class_fc_feed_acds]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_acds(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_sk_mft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_sk_mft_bnl(inpath:String):Dataset[class_fc_feed_rs_components_sk_mft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_sk_mft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_sk_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_sk_findchips(inpath:String):Dataset[class_fc_feed_distrelec_sk_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_sk_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tedss(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tedss(inpath:String):Dataset[class_fc_feed_tedss]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tedss(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_toponebuy(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_toponebuy(inpath:String):Dataset[class_fc_feed_toponebuy]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_toponebuy(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_arrow_china(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_arrow_china(inpath:String):Dataset[class_fc_feed_arrow_china]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_arrow_china(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chipone(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chipone(inpath:String):Dataset[class_fc_feed_chipone]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chipone(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_glyn(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_glyn(inpath:String):Dataset[class_fc_feed_glyn]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_glyn(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_enteermall(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_enteermall(inpath:String):Dataset[class_fc_feed_enteermall]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_enteermall(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rcelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rcelec(inpath:String):Dataset[class_fc_feed_rcelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rcelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_utmel(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_utmel(inpath:String):Dataset[class_fc_feed_utmel]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_utmel(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_avnet_asia_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_avnet_asia_bnl(inpath:String):Dataset[class_fc_feed_avnet_asia_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_avnet_asia_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_inductors(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_inductors(inpath:String):Dataset[class_fc_feed_inductors]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_inductors(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_tencell(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_tencell(inpath:String):Dataset[class_fc_feed_tencell]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_tencell(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_acmechip_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_acmechip_oems(inpath:String):Dataset[class_fc_feed_acmechip_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_acmechip_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_nz(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_nz(inpath:String):Dataset[class_fc_feed_rspro_nz]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_nz(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_mps(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_mps(inpath:String):Dataset[class_fc_feed_mps]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_mps(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_digikey_uk_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_digikey_uk_bnl(inpath:String):Dataset[class_fc_feed_digikey_uk_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_digikey_uk_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_era(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_era(inpath:String):Dataset[class_fc_feed_era]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_era(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ameya_fc_cn(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ameya_fc_cn(inpath:String):Dataset[class_fc_feed_ameya_fc_cn]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ameya_fc_cn(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rochester_kr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rochester_kr(inpath:String):Dataset[class_fc_feed_rochester_kr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rochester_kr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ukserfala(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ukserfala(inpath:String):Dataset[class_fc_feed_ukserfala]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ukserfala(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_coilcraft_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_coilcraft_bnl(inpath:String):Dataset[class_fc_feed_coilcraft_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_coilcraft_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_cytech(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_cytech(inpath:String):Dataset[class_fc_feed_cytech]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_cytech(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_apvm(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_apvm(inpath:String):Dataset[class_fc_feed_apvm]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_apvm(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_cny_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_cny_oems(inpath:String):Dataset[class_fc_feed_chip1stop_cny_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_cny_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_tr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_tr(inpath:String):Dataset[class_fc_feed_farnell_tr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_tr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_pt(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_pt(inpath:String):Dataset[class_fc_feed_rs_components_pt]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_pt(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_taprobain(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_taprobain(inpath:String):Dataset[class_fc_feed_taprobain]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_taprobain(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_hu_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_hu_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_hu_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_hu_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_oems_ru(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_oems_ru(inpath:String):Dataset[class_fc_feed_comsit_oems_ru]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_oems_ru(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_maxim_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_maxim_bnl(inpath:String):Dataset[class_fc_feed_rs_components_maxim_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_maxim_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_comsit_fc_fr(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_comsit_fc_fr(inpath:String):Dataset[class_fc_feed_comsit_fc_fr]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_comsit_fc_fr(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_allied_findchips_ex(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_allied_findchips_ex(inpath:String):Dataset[class_fc_feed_allied_findchips_ex]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_allied_findchips_ex(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_icsole(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_icsole(inpath:String):Dataset[class_fc_feed_icsole]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_icsole(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_shortec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_shortec(inpath:String):Dataset[class_fc_feed_shortec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_shortec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_cisemiconductors(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_cisemiconductors(inpath:String):Dataset[class_fc_feed_cisemiconductors]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_cisemiconductors(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_il(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_il(inpath:String):Dataset[class_fc_feed_farnell_il]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_il(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_heilind_asia(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_heilind_asia(inpath:String):Dataset[class_fc_feed_heilind_asia]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_heilind_asia(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_supertronic(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_supertronic(inpath:String):Dataset[class_fc_feed_supertronic]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_supertronic(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_ro_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_ro_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_ro_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_ro_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_heqingelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_heqingelec(inpath:String):Dataset[class_fc_feed_heqingelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_heqingelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_hsictrading(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_hsictrading(inpath:String):Dataset[class_fc_feed_hsictrading]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_hsictrading(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_arrow_bnl_pemco(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_arrow_bnl_pemco(inpath:String):Dataset[class_fc_feed_arrow_bnl_pemco]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_arrow_bnl_pemco(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_goodiclink(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_goodiclink(inpath:String):Dataset[class_fc_feed_goodiclink]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_goodiclink(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_hsmelect(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_hsmelect(inpath:String):Dataset[class_fc_feed_hsmelect]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_hsmelect(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ti_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ti_bnl(inpath:String):Dataset[class_fc_feed_ti_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ti_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_smrelec(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_smrelec(inpath:String):Dataset[class_fc_feed_smrelec]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_smrelec(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rochester_jp(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rochester_jp(inpath:String):Dataset[class_fc_feed_rochester_jp]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rochester_jp(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_winsource_cse(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_winsource_cse(inpath:String):Dataset[class_fc_feed_winsource_cse]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_winsource_cse(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_lvy(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_lvy(inpath:String):Dataset[class_fc_feed_lvy]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_lvy(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_jpy_multi(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_jpy_multi(inpath:String):Dataset[class_fc_feed_chip1stop_jpy_multi]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_jpy_multi(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_hu_findchips(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_hu_findchips(inpath:String):Dataset[class_fc_feed_distrelec_hu_findchips]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_hu_findchips(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_fanco(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_fanco(inpath:String):Dataset[class_fc_feed_fanco]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_fanco(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rs_components_au(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rs_components_au(inpath:String):Dataset[class_fc_feed_rs_components_au]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rs_components_au(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_eve(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_eve(inpath:String):Dataset[class_fc_feed_eve]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_eve(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_teltek(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_teltek(inpath:String):Dataset[class_fc_feed_teltek]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_teltek(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_technitool(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_technitool(inpath:String):Dataset[class_fc_feed_technitool]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_technitool(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ardusimple_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ardusimple_oems(inpath:String):Dataset[class_fc_feed_ardusimple_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ardusimple_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_acmechip(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_acmechip(inpath:String):Dataset[class_fc_feed_acmechip]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_acmechip(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ntd(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ntd(inpath:String):Dataset[class_fc_feed_ntd]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ntd(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_kailiyuan(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_kailiyuan(inpath:String):Dataset[class_fc_feed_kailiyuan]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_kailiyuan(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_handchain(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_handchain(inpath:String):Dataset[class_fc_feed_handchain]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_handchain(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_farnell_rohde_bnl_uk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_farnell_rohde_bnl_uk(inpath:String):Dataset[class_fc_feed_farnell_rohde_bnl_uk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_farnell_rohde_bnl_uk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_conrad(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_conrad(inpath:String):Dataset[class_fc_feed_conrad]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_conrad(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_jpy(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_jpy(inpath:String):Dataset[class_fc_feed_chip1stop_jpy]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_jpy(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_distrelec_nl_oemstrade(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_distrelec_nl_oemstrade(inpath:String):Dataset[class_fc_feed_distrelec_nl_oemstrade]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_distrelec_nl_oemstrade(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rspro_pl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rspro_pl(inpath:String):Dataset[class_fc_feed_rspro_pl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rspro_pl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_olc_oems(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_olc_oems(inpath:String):Dataset[class_fc_feed_olc_oems]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_olc_oems(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_newark_mx(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_newark_mx(inpath:String):Dataset[class_fc_feed_newark_mx]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_newark_mx(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_liangxin(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_liangxin(inpath:String):Dataset[class_fc_feed_liangxin]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_liangxin(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_suntronic(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_suntronic(inpath:String):Dataset[class_fc_feed_suntronic]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_suntronic(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_cdi(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_cdi(inpath:String):Dataset[class_fc_feed_cdi]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_cdi(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_usd_bnl_test(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_usd_bnl_test(inpath:String):Dataset[class_fc_feed_chip1stop_usd_bnl_test]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_usd_bnl_test(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_element14_hk(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_element14_hk(inpath:String):Dataset[class_fc_feed_element14_hk]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_element14_hk(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_chip1stop_cny_oems_2(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_chip1stop_cny_oems_2(inpath:String):Dataset[class_fc_feed_chip1stop_cny_oems_2]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_chip1stop_cny_oems_2(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_venkel(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_venkel(inpath:String):Dataset[class_fc_feed_venkel]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_venkel(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_smartpioneer(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_smartpioneer(inpath:String):Dataset[class_fc_feed_smartpioneer]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_smartpioneer(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_interine(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_interine(inpath:String):Dataset[class_fc_feed_interine]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_interine(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_ickey_china(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_ickey_china(inpath:String):Dataset[class_fc_feed_ickey_china]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_ickey_china(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_rochester_mx_bnl(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_rochester_mx_bnl(inpath:String):Dataset[class_fc_feed_rochester_mx_bnl]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_rochester_mx_bnl(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_teconn_bnl_2(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_teconn_bnl_2(inpath:String):Dataset[class_fc_feed_teconn_bnl_2]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_teconn_bnl_2(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
case class class_fc_feed_techdesign_bnl_winbond(distributor_uid:Integer,part_uid:Integer,distributor_name:String,dist_mfr_name:String,mfr_part_number:String,dist_item_no:String,description:String,stock_qty:Long,stock_indicator:String,stock_flag:String,pricing:String,buy_now_url:String,oems_buy_now_url:String,detail_url:String,value1:String,value2:String,value3:String,value4:String,value5:String,value6:String,value7:String,value8:String,value9:String,value10:String,active:Integer,fuid:String,last_modified:String,currency:String,min_qty:Integer,mult_qty:Integer,container:String,pipeline:String,lead_time:Integer,date_code:String,rohs:String,pb_free:String,image_url:String,pricing_data:String,rohs_details:String,pb_free_details:String,sf_category:String,sf_class:String,reach:String,record_id:Long)
def convert_fc_feed_techdesign_bnl_winbond(inpath:String):Dataset[class_fc_feed_techdesign_bnl_winbond]={
  val lines = spark.read.format("text").option("delimiter","\t").load(inpath)
  val df = lines.map(line=>{
    val oldfields = line(0).toString.split("\t")
    var fields = oldfields
    if(oldfields.length<44) fields = oldfields.padTo(44,null)
    class_fc_feed_techdesign_bnl_winbond(str2int(fields(0)),str2int(fields(1)),checknull(fields(2)),checknull(fields(3)),checknull(fields(4)),checknull(fields(5)),checknull(fields(6)),str2long(fields(7)),checknull(fields(8)),checknull(fields(9)),checknull(fields(10)),checknull(fields(11)),checknull(fields(12)),checknull(fields(13)),checknull(fields(14)),checknull(fields(15)),checknull(fields(16)),checknull(fields(17)),checknull(fields(18)),checknull(fields(19)),checknull(fields(20)),checknull(fields(21)),checknull(fields(22)),checknull(fields(23)),str2int(fields(24)),checknull(fields(25)),checknull(fields(26)),checknull(fields(27)),str2int(fields(28)),str2int(fields(29)),checknull(fields(30)),checknull(fields(31)),str2int(fields(32)),checknull(fields(33)),checknull(fields(34)),checknull(fields(35)),checknull(fields(36)),checknull(fields(37)),checknull(fields(38)),checknull(fields(39)),checknull(fields(40)),checknull(fields(41)),checknull(fields(42)),str2long(fields(43)))})
  df
}
